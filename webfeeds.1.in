.TH WEBFEEDS 1 "3 February 2023" 1.0
.SH NAME
webfeeds \- collect web feed titles and links
.SH SYNOPSIS
.B webfeeds
.RB [ \-0 ]
.RB [ \-l
.IR directory ]
.I database
.SH DESCRIPTION
.B webfeeds
reads from standard input newline separated URLs and potentially produces a
list of directories under the provided
.I database
directory.
.P
Empty lines or lines beginning with a
.I #
character are ignored.  Any text after a URL is also ignored.
.P
During operation if a feed was found to have new articles then the directory to
its database entry will be written to standard output.  Inside this directory
there will exist the file
.I new
containing the recent entries.  The counterpart,
.IR archive ,
will contain all entries seen thusfar.
.P
The entries are separated by newlines and interspersed by spaces.  It consists
of the date in RFC3339 format at UTC0, followed by the URL and then the title.
.P
For example:
.P
.EE
    1970-01-01T01:00:00Z http://example.com/article Article Title for Example Entry
.EX
.P
.SH OPTIONS
.TP
.B \-0
The database directories written to standard output will be separated by a null
byte instead of a newline.
.TP
.BI \-l " directory"
The location of the XSLT files (intended for debugging).
.SH EXIT STATUS
.B webfeeds
usually returns
.B zero
but errors from tools used within are able to write their own messages to
standard error.
.SH FILES
.TP
.B \%M4_XSLTDIR
The directory containing the XSLT scripts used to transform the XML and write
formatted entries.
.TP
.B \%database
The directory provided on the command-line which will be populated by the files
used to track entries from web feeds.
.P
For each web feed provided the
.I domain
from the channel's URL and its
.I title
will be joined to create directories under which the
.IR new ", " archive " and "storage
files are kept.
.TP
.B \%database/db/domain/title/new
The file containing newly discovered entries.
.TP
.B \%database/db/domain/title/archive
The file containing roughly 3000 entries seen heretofore before being placed in
storage.
.TP
.B \%database/db/domain/title/storage
The directory containing compressed archives which are produced once the number
of entries in the
.I archive
file exceeds 3000.
.P
The files
.IR etag ", " xml " and " recent
are used for internal details may also be found.  Here the directory under
.I xml
is constructed with the URL as-is excluding the scheme part.
.TP
.B \%database/xml/url/etag
The file used for etag values when querying servers for new additions in order
to mitigate unnecessary bandwidth use.
.TP
.B \%database/xml/url/xml
The raw web feed XML data from which pertinent information is extracted.  This
file is removed immediately afterwards and should not be present under normal
circumstances.
.TP
.B \%database/db/domain/title/recent
The file contains the freshly parsed results and used to produce the new file.
It is removed immediately afterwards and should not be present under normal
circumstances.
.SH NOTES
Each time
.B webfeeds
is run the corresponding
.I new
files will be overwritten.  As a result it will not be able to use this file
as a means to track unread entries if it has not been processed before
subsequent runs.  The missed entries will nevertheless be found in the
.I archive
file or within the
.I storage
directory.
.SH EXAMPLES
The essential workflow of
.B webfeeds
can be demonstrated as follows:
.P
.EX
    $ cat feeds
    # linux news
    https://lwn.net/headlines/newrss

    $ mkdir database
    $ webfeeds database < feeds
    database/lwn.net/LWN.net

    $ cat database/db/lwn.net/LWN.net/new
    2022-02-14T14:50:31Z https://lwn.net/Articles/884757/ Security updates for Monday
    2022-02-14T00:15:57Z https://lwn.net/Articles/884689/ Kernel prepatch 5.17-rc4
    2022-02-11T16:46:15Z https://lwn.net/Articles/884301/ [$] Debian reconsiders NEW review
    ...
.EE
.P
Alone this may not be particularly comfortable;
.B webfeeds
was designed to separate retrieval and storage from presentation.  Simple
scripts can be used to provide a feed reader, for example:
.P
.EX
    #!/bin/bash --

    db=$PWD/database
    mkdir -p -- "$db"

    while IFS= read -rd '' db; do
        printf -v prompt '[%s] %s' "$(wc -l < "$db"/new)" "${db##*/}"
        printf '%s\en' "$prompt" "${prompt//?/=}" "$(< "$db"/new)"
        printf '\ea'
    done < <(nice webfeeds -0 "$database" < feeds)
.EE
.SH SOURCE
.UR https://github.com/Earnestly/webfeeds
.UE
